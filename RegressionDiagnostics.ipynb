{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Multicollinearity diagnostics \n",
    "The first step in multicollinearity diagnostics is looking at the pairwise correlations coefficients. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = objectOrientedEDA.data.loc[:, objectOrientedEDA.data.columns != 'price']\n",
    "corr_matrix = objectOrientedEDA.data.loc[:, objectOrientedEDA.data.columns != 'price'].corr(method='pearson')\n",
    "fig, ax = plt.subplots(figsize=(10,10)) \n",
    "sns.heatmap(corr_matrix, annot=True, ax=ax)\n",
    "#sns.pairplot(objectOrientedEDA.data[['cleaning_fee', 'accommodates', 'bathrooms']])"
   ]
  },
  {
   "source": [
    "Notice how 'accommodates', 'bathrooms', 'bedrooms', and 'bed' are so strongly correlated. \n",
    "\n",
    "There is also some correlation between 'accommodates' and 'cleaning_fee' (0.5) and then between 'accommodates' and 'bathrooms' (0.47)<br/n>. These values are not too high, but if they were, we would have had to do a more through diagnostics by looking at the Variance Inflation Factors (VIF)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Heteroscedasticity diagnostics \n",
    "The most basic (informal) way heteroscedasticity diagnostics is to plot the least squares residuals vs the explanatory variable. If there is an evident pattern in the plot, then heteroskedasticity is present. <br />\n",
    "\n",
    "https://towardsdatascience.com/assumptions-of-linear-regression-algorithm-ed9ea32224e1\n",
    "\n",
    "\n",
    "There are more formal ways of detecting heteroscedasticity, such as White and Breusch-Pagan tests, but we will skip them for now and look at only residual plots."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import ResidualsPlot\n",
    "from sklearn.linear_model import LinearRegression\n",
    "Lr = LinearRegression()\n",
    "visualizer = ResidualsPlot(Lr)\n",
    "#series = objectOrientedEDA.data[['price']].iloc[:,0]\n",
    "feature_tmp = objectOrientedEDA.data[['accommodates']].to_numpy().reshape(-1, 1)\n",
    "target_tmp = objectOrientedEDA.data[['price']].to_numpy().reshape(-1, 1)\n",
    "\n",
    "visualizer.fit(feature_tmp, target_tmp, )\n",
    "visualizer.show()"
   ]
  },
  {
   "source": [
    "Now that the data has been explored and cleaned up, we are ready to continue with fitting different models. All the methods responsible for fitting the model and making predictions will be invoked through an object of the class FitandPredict. That class inherits from another class called FeatureSelection, which implement methods responsible for feature selection.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}